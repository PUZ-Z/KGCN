{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KGCN ë…¼ë¬¸ ë¦¬ë·° & ì½”ë“œ ì‘ì„±\n",
    "**KGCN: Simplifying and Powering Graph Convolution Network for Recommendation**  \n",
    "*Hongwei Wang et al. (2019)*  \n",
    "ğŸ”— [ë…¼ë¬¸ ë§í¬](https://arxiv.org/abs/1904.12575)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Problem Formulation\n",
    "\n",
    "*ëª©í‘œ : ì‚¬ìš©ì uê°€ ì•„ì´í…œ vì— ê´€ì‹¬ ìˆì„ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜*\n",
    "$$\\hat{y}_{uv} = F(u,v | Î˜, Y, G)$$\n",
    "- Y : ì‚¬ìš©ì-ì•„ì´í…œ ìƒí˜¸ì‘ìš© í–‰ë ¬ (ì˜ˆ: í´ë¦­, í‰ê°€)\n",
    "- G : ì§€ì‹ ê·¸ë˜í”„ (KG), ì‚¼ì¤‘í•­(triple : head, relation, tail)ì˜ ì§‘í•©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 KGCN Layer (ëª¨ë¸ êµ¬ì„± ìš”ì†Œ)\n",
    "\n",
    "*1. ê´€ê³„ ì¤‘ìš”ë„ ê³„ì‚° (ì‚¬ìš©ì u, ê´€ê³„ r)*\n",
    "$$\\pi_{ur} = g(u,r)$$\n",
    "\n",
    "*2. ì´ì›ƒ ë…¸ë“œ ì§‘ê³„ (attention ê°€ì¤‘ì¹˜ í¬í•¨)*\n",
    "$$v_u^{N(v)} = \\sigma_{e\\in{N(v)}}\\tilde{\\pi}_{ur}â‹…e$$\n",
    "$$\\tilde{\\pi}_{ur}=\\frac{exp(\\pi_{ur})}{\\sum\\nolimits_{e'}exp(\\pi_{ur'})}$$\n",
    "\n",
    "*3. Aggregation ë°©ì‹ 3ê°€ì§€*\n",
    "- Sum : $ReLU(W(v+v_u^{N(v)})+b)$\n",
    "- Concat : $ReLU(W[v;v_u^{N(v)}]+b)$\n",
    "- Neighbor : $ReLU(Wv_u^{N(v)}+b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Learning Algorithm (í•™ìŠµ ì•Œê³ ë¦¬ì¦˜)\n",
    "\n",
    "*ë°˜ë³µ êµ¬ì¡°*\n",
    "KGCNì€ ì—¬ëŸ¬ ê³„ì¸µ(hop)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ '0-hop â†’ 1-hop â†’ ...'ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì´ì›ƒ ì •ë³´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì „íŒŒ ë° ì§‘ê³„\n",
    "$$\\hat{y}_{uv}=f(u, v_u^{(h)})$$\n",
    "\n",
    "*í•™ìŠµ ì†ì‹¤ í•¨ìˆ˜*\n",
    "- Cross Entropy + Negative Sampling + L2 ì •ê·œí™” í¬í•¨\n",
    "$$L = \\sum_{u}\\begin{bmatrix}\\sum_{v:y_{uv}=1}J(y_{uv}, \\hat{y}_{uv})-\\sum_{i=1}^{T_u}\\mathbb{E}_{vi~P(v)}J(0,\\hat{y}_(uvi))\\end{bmatrix}+\\lambda||F||_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\"))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book - Crossing ëª¨ë¸ ì„¤ì • (Hyperparameter)\n",
    "\n",
    "|í•­ëª©|ì„¤ì •|\n",
    "|:---:|:---:|\n",
    "ì„ë² ë”© ì°¨ì› | 64\n",
    "í•™ìŠµë¥  | 0.0002\n",
    "Optimizer | Adam\n",
    "ì •ê·œí™” ê³„ìˆ˜ (L2) | 2e-5\n",
    "Negative Sampling | 1:1 ë¹„ìœ¨ë¡œ ìƒ˜í”Œë§\n",
    "ë°°ì¹˜ ì‚¬ì´ì¦ˆ | 256\n",
    "í•™ìŠµ Epoch | ìµœëŒ€ 1000 (ì¼ë°˜ì ìœ¼ë¡œ 200~400)\n",
    "ë ˆì´ì–´ ìˆ˜ (Receptive Field Depth, H) | 1\n",
    "ì´ì›ƒ ìƒ˜í”Œë§ ìˆ˜ (K) | 8\n",
    "ì´ˆê¸°í™” ë°©ì‹ | Xavier Uniform (ëª…ì‹œëŠ” ì—†ì§€ë§Œ ì¼ë°˜ì ì¸ ì´ˆê¸°í™” ë°©ì‹ìœ¼ë¡œ ì¶”ì •ë¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'item2id_path': 'data/item_index2entity_id.txt',\n",
    "    'kg_path': 'data/kg.txt',\n",
    "    'rating_path': 'data/user_artists.dat',\n",
    "    'rating_sep': '\\t',\n",
    "    'threshold': 0.0,\n",
    "    \n",
    "    'embedding_dim': 16,\n",
    "    'n_epochs': 20,\n",
    "    'neighbor_sample_size': 8,\n",
    "    'n_iter': 1,\n",
    "    'batch_size': 256,\n",
    "    'l2_weight': 1e-4,\n",
    "    'lr': 5e-4,\n",
    "    'train_ratio': 0.8,\n",
    "    'aggregator': 'sum',\n",
    "    'device': 'mps'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGDataLoader:\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg  # ì„¤ì • ì €ì¥\n",
    "\n",
    "        # íŒŒì¼ ë¡œë“œ\n",
    "        df_item2id = pd.read_csv(self.cfg['item2id_path'], sep='\\t', header=None, names=['item', 'id'])  # ì•„ì´í…œâ†’ì—”í‹°í‹° ë§¤í•‘\n",
    "        df_kg = pd.read_csv(self.cfg['kg_path'], sep='\\t', header=None, names=['head', 'relation', 'tail'])  # ì§€ì‹ ê·¸ë˜í”„\n",
    "        df_rating = pd.read_csv(self.cfg['rating_path'], sep=self.cfg['rating_sep'], \n",
    "                                names=['userID', 'itemID', 'rating'], skiprows=1)  # ì‚¬ìš©ì-ì•„ì´í…œ í‰ì \n",
    "\n",
    "        # ë§¤í•‘ì— ì¡´ì¬í•˜ëŠ” ì•„ì´í…œë§Œ í•„í„°ë§\n",
    "        df_rating = df_rating[df_rating['itemID'].isin(df_item2id['item'])]\n",
    "        df_rating.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # ë°ì´í„°í”„ë ˆì„ ì €ì¥\n",
    "        self.df_item2id = df_item2id\n",
    "        self.df_kg = df_kg\n",
    "        self.df_rating = df_rating\n",
    "\n",
    "        # ì¸ì½”ë” ì¤€ë¹„\n",
    "        self.user_encoder = LabelEncoder()\n",
    "        self.entity_encoder = LabelEncoder()\n",
    "        self.relation_encoder = LabelEncoder()\n",
    "\n",
    "        # ID ì¸ì½”ë”© ì‹¤í–‰\n",
    "        self._encoding()\n",
    "\n",
    "    def _encoding(self): # userID, entityID, relationì„ ì •ìˆ˜ë¡œ ì¸ì½”ë”©\n",
    "        self.user_encoder.fit(self.df_rating['userID'])\n",
    "        self.entity_encoder.fit(pd.concat([self.df_item2id['id'], self.df_kg['head'], self.df_kg['tail']]))\n",
    "        self.relation_encoder.fit(self.df_kg['relation'])\n",
    "\n",
    "        # ë³€í™˜ ì ìš©\n",
    "        self.df_kg['head'] = self.entity_encoder.transform(self.df_kg['head'])\n",
    "        self.df_kg['tail'] = self.entity_encoder.transform(self.df_kg['tail'])\n",
    "        self.df_kg['relation'] = self.relation_encoder.transform(self.df_kg['relation'])\n",
    "\n",
    "    def _build_dataset(self): # positive + negative ìƒ˜í”Œ ìƒì„±í•˜ì—¬ í•™ìŠµìš© ë°ì´í„°ì…‹ êµ¬ì„±\n",
    "        print('Build dataset dataframe ...', end=' ')\n",
    "        df_dataset = pd.DataFrame()\n",
    "\n",
    "        # ì‚¬ìš©ì ID ì¸ì½”ë”©\n",
    "        df_dataset['userID'] = self.user_encoder.transform(self.df_rating['userID'])\n",
    "\n",
    "        # ì•„ì´í…œ ë¬¸ìì—´ì„ entity IDë¡œ ë§¤í•‘\n",
    "        item2id_dict = dict(zip(self.df_item2id['item'], self.df_item2id['id']))\n",
    "        self.df_rating['itemID'] = self.df_rating['itemID'].apply(lambda x: item2id_dict[x])\n",
    "\n",
    "        # ì—”í‹°í‹° ì¸ì½”ë”©\n",
    "        df_dataset['itemID'] = self.entity_encoder.transform(self.df_rating['itemID'])\n",
    "\n",
    "        # í‰ì ì„ ì„ê³„ê°’ ê¸°ì¤€ìœ¼ë¡œ ì´ì§„ ë¼ë²¨ ìƒì„±\n",
    "        df_dataset['label'] = self.df_rating['rating'].apply(lambda x: 0 if x < self.cfg['threshold'] else 1)\n",
    "\n",
    "        # positiveë§Œ ì‚¬ìš©\n",
    "        df_dataset = df_dataset[df_dataset['label'] == 1]\n",
    "\n",
    "        # ì „ì²´ ì—”í‹°í‹° ì§‘í•©ì—ì„œ negative ìƒ˜í”Œë§\n",
    "        full_item_set = set(range(len(self.entity_encoder.classes_)))\n",
    "        user_list, item_list, label_list = [], [], []\n",
    "        for user, group in df_dataset.groupby('userID'):\n",
    "            item_set = set(group['itemID'])  # positive ì•„ì´í…œ ì§‘í•©\n",
    "            negative_set = full_item_set - item_set  # negative í›„ë³´\n",
    "            negative_sampled = random.sample(list(negative_set), len(item_set))  # ê°™ì€ ìˆ˜ ë§Œí¼ ìƒ˜í”Œë§\n",
    "\n",
    "            # negative ìƒ˜í”Œ ì €ì¥\n",
    "            user_list.extend([user] * len(negative_sampled))\n",
    "            item_list.extend(negative_sampled)\n",
    "            label_list.extend([0] * len(negative_sampled))\n",
    "\n",
    "        # negativeë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê³  ê²°í•©\n",
    "        negative = pd.DataFrame({'userID': user_list, 'itemID': item_list, 'label': label_list})\n",
    "        df_dataset = pd.concat([df_dataset, negative])\n",
    "\n",
    "        # ì…”í”Œ ë° ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "        df_dataset = df_dataset.sample(frac=1, replace=False, random_state=999)\n",
    "        df_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        print('Done')\n",
    "        return df_dataset\n",
    "\n",
    "    def _construct_kg(self): # ì–‘ë°©í–¥ knowledge graph ë”•ì…”ë„ˆë¦¬ êµ¬ì„±\n",
    "        print('Construct knowledge graph ...', end=' ')\n",
    "        kg = dict()\n",
    "        for i in range(len(self.df_kg)):\n",
    "            head = self.df_kg.iloc[i]['head']\n",
    "            relation = self.df_kg.iloc[i]['relation']\n",
    "            tail = self.df_kg.iloc[i]['tail']\n",
    "\n",
    "            # head â†’ tail\n",
    "            if head in kg:\n",
    "                kg[head].append((relation, tail))\n",
    "            else:\n",
    "                kg[head] = [(relation, tail)]\n",
    "\n",
    "            # tail â†’ head (ì–‘ë°©í–¥)\n",
    "            if tail in kg:\n",
    "                kg[tail].append((relation, head))\n",
    "            else:\n",
    "                kg[tail] = [(relation, head)]\n",
    "\n",
    "        print('Done')\n",
    "        return kg\n",
    "\n",
    "    def load_dataset(self): # í•™ìŠµìš© ì‚¬ìš©ì-ì•„ì´í…œ ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "        return self._build_dataset()\n",
    "\n",
    "    def load_kg(self): # ì§€ì‹ ê·¸ë˜í”„ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ\n",
    "        return self._construct_kg()\n",
    "\n",
    "    def get_encoders(self): # user, entity, relation ì¸ì½”ë” ë°˜í™˜\n",
    "        return (self.user_encoder, self.entity_encoder, self.relation_encoder)\n",
    "\n",
    "    def get_num(self): # ê° ì¸ì½”ë”ì˜ í´ë˜ìŠ¤ ìˆ˜ ë°˜í™˜ (ëª¨ë¸ ì…ë ¥ ì°¨ì› ê³„ì‚°ìš©)\n",
    "        return (len(self.user_encoder.classes_), \n",
    "                len(self.entity_encoder.classes_), \n",
    "                len(self.relation_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build dataset dataframe ... Done\n",
      "ë ˆì´ë¸” ë¶„í¬:\n",
      "label\n",
      "1    21173\n",
      "0    21173\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ë ˆì´ë¸” ë¹„ìœ¨ (%):\n",
      "label\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n",
      "userID    int64\n",
      "itemID    int64\n",
      "label     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ì„¤ì • ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ KGDataLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "data_loader = KGDataLoader(cfg=config)\n",
    "\n",
    "# í•™ìŠµìš© ì‚¬ìš©ì-ì•„ì´í…œ ë°ì´í„°ì…‹ì„ ìƒì„± (positive + negative ìƒ˜í”Œ í¬í•¨)\n",
    "df_dataset = data_loader.load_dataset()\n",
    "\n",
    "# ë ˆì´ë¸”(positive: 1, negative: 0) ë¶„í¬ ì¶œë ¥\n",
    "print(\"ë ˆì´ë¸” ë¶„í¬:\")\n",
    "print(df_dataset['label'].value_counts())\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ì¤‘ ë ˆì´ë¸” ë¹„ìœ¨ (%)ë¡œ ì¶œë ¥\n",
    "print(\"\\në ˆì´ë¸” ë¹„ìœ¨ (%):\")\n",
    "print(df_dataset['label'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… í™•ì¸\n",
    "print(df_dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, dim, aggregator):\n",
    "        super(Aggregator, self).__init__()\n",
    "        self.batch_size = batch_size  # ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°\n",
    "        self.dim = dim                # ì„ë² ë”© ì°¨ì›\n",
    "        self.aggregator = aggregator  # aggregation ë°©ì‹: sum / concat / neighbor-only\n",
    "\n",
    "        # aggregator ì¢…ë¥˜ì— ë”°ë¼ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "        if aggregator == 'concat':\n",
    "            # self ì„ë² ë”© + ì´ì›ƒ ì„ë² ë”©ì„ concatí•˜ë©´ ì°¨ì›ì´ 2ë°°ê°€ ë˜ë¯€ë¡œ\n",
    "            self.weights = torch.nn.Linear(2 * dim, dim, bias=True)\n",
    "        else:\n",
    "            # sum or neighbor-onlyì¸ ê²½ìš°ëŠ” ì°¨ì› ê·¸ëŒ€ë¡œ\n",
    "            self.weights = torch.nn.Linear(dim, dim, bias=True)\n",
    "        \n",
    "    def forward(self, self_vectors, neighbor_vectors, neighbor_relations, user_embeddings, act):\n",
    "        # self_vectors: [batch_size, -1, dim]   â†’ í˜„ì¬ ì—”í‹°í‹° (ë…¸ë“œ) ì„ë² ë”©\n",
    "        # neighbor_vectors: [batch_size, -1, n_neighbor, dim] â†’ ì´ì›ƒ ì—”í‹°í‹° ì„ë² ë”©\n",
    "        # neighbor_relations: [batch_size, -1, n_neighbor, dim] â†’ ì´ì›ƒ ê´€ê³„ ì„ë² ë”©\n",
    "        # user_embeddings: [batch_size, dim] â†’ ì‚¬ìš©ì ì„ë² ë”© (user-aware attentionì— ì‚¬ìš©)\n",
    "        # act: í™œì„±í™” í•¨ìˆ˜ (ì˜ˆ: torch.relu)\n",
    "        batch_size = user_embeddings.size(0)\n",
    "\n",
    "        # batch_sizeê°€ ë³€í•  ìˆ˜ ìˆì–´ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        # ì´ì›ƒ ì„ë² ë”©ì„ user-aware ë°©ì‹ìœ¼ë¡œ í•©ì¹˜ëŠ” ê³¼ì •\n",
    "        neighbors_agg = self._mix_neighbor_vectors(neighbor_vectors, neighbor_relations, user_embeddings)\n",
    "\n",
    "        # aggregation ë°©ì‹ì— ë”°ë¼ self vectorì™€ í•©ì¹˜ëŠ” ë°©ì‹ ë‹¬ë¼ì§\n",
    "        if self.aggregator == 'sum':\n",
    "            # self + neighbor í•©ì‚°\n",
    "            output = (self_vectors + neighbors_agg).view((-1, self.dim))\n",
    "\n",
    "        elif self.aggregator == 'concat':\n",
    "            # selfì™€ neighborë¥¼ concatí•œ í›„ projection\n",
    "            output = torch.cat((self_vectors, neighbors_agg), dim=-1)  # [batch, -, 2*dim]\n",
    "            output = output.view((-1, 2 * self.dim))\n",
    "\n",
    "        else:\n",
    "            # neighbor-only (self vectorëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    "            output = neighbors_agg.view((-1, self.dim))\n",
    "\n",
    "        # projection + í™œì„±í™”\n",
    "        output = self.weights(output)  # [batch * -, dim]\n",
    "        return act(output.view((self.batch_size, -1, self.dim)))  # ë‹¤ì‹œ ë°°ì¹˜ í˜•íƒœë¡œ reshape\n",
    "\n",
    "    def _mix_neighbor_vectors(self, neighbor_vectors, neighbor_relations, user_embeddings):\n",
    "        # ì‚¬ìš©ì-ê´€ê³„ì— ë”°ë¼ ì´ì›ƒ ë…¸ë“œë“¤ì„ ê°€ì¤‘ í‰ê· í•¨ â†’ user-aware attentionìœ¼ë¡œ neighbor vector ì§‘ê³„\n",
    "        # [batch, dim] â†’ [batch, 1, 1, dim]\n",
    "        user_embeddings = user_embeddings.view((self.batch_size, 1, 1, self.dim))\n",
    "\n",
    "        # userì™€ relation ê°„ì˜ ì ê³± score ê³„ì‚° â†’ [batch, -, n_neighbor]\n",
    "        user_relation_scores = (user_embeddings * neighbor_relations).sum(dim=-1)\n",
    "\n",
    "        # softmaxë¡œ attention weight ê³„ì‚°\n",
    "        user_relation_scores_normalized = F.softmax(user_relation_scores, dim=-1)\n",
    "\n",
    "        # [batch, -, n_neighbor] â†’ [batch, -, n_neighbor, 1]\n",
    "        user_relation_scores_normalized = user_relation_scores_normalized.unsqueeze(dim=-1)\n",
    "\n",
    "        # attention weight * neighbor vector â†’ ê°€ì¤‘ í‰ê·  [batch, -, dim]\n",
    "        neighbors_aggregated = (user_relation_scores_normalized * neighbor_vectors).sum(dim=2)\n",
    "\n",
    "        return neighbors_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGCN(torch.nn.Module):\n",
    "    def __init__(self, num_user, num_ent, num_rel, kg, config):\n",
    "        super(KGCN, self).__init__()\n",
    "        self.num_user = num_user\n",
    "        self.num_ent = num_ent\n",
    "        self.num_rel = num_rel\n",
    "        self.n_iter = config['n_iter']                           # GCN ë ˆì´ì–´ ìˆ˜\n",
    "        self.batch_size = config['batch_size']                  # ë°°ì¹˜ í¬ê¸°\n",
    "        self.dim = config['embedding_dim']                      # ì„ë² ë”© ì°¨ì›\n",
    "        self.n_neighbor = config['neighbor_sample_size']        # ì´ì›ƒ ìˆ˜\n",
    "        self.kg = kg\n",
    "        self.device = torch.device(config['device'])            # device ì„¤ì •\n",
    "\n",
    "        # Aggregator ì¸ìŠ¤í„´ìŠ¤\n",
    "        self.aggregator = Aggregator(self.batch_size, self.dim, config['aggregator'])\n",
    "\n",
    "        self._gen_adj()\n",
    "\n",
    "        # ì„ë² ë”© ë ˆì´ì–´\n",
    "        self.usr = torch.nn.Embedding(num_user, self.dim)\n",
    "        self.ent = torch.nn.Embedding(num_ent, self.dim)\n",
    "        self.rel = torch.nn.Embedding(num_rel, self.dim)\n",
    "\n",
    "    def _gen_adj(self): # ì—”í‹°í‹°ë§ˆë‹¤ ê³ ì • ê°œìˆ˜ì˜ ì´ì›ƒ ì—”í‹°í‹° ë° ê´€ê³„ë¥¼ ìƒ˜í”Œë§í•˜ì—¬ ì¸ì ‘í–‰ë ¬ ìƒì„±\n",
    "        self.adj_ent = torch.empty(self.num_ent, self.n_neighbor, dtype=torch.long)\n",
    "        self.adj_rel = torch.empty(self.num_ent, self.n_neighbor, dtype=torch.long)\n",
    "\n",
    "        for e in self.kg:\n",
    "            if len(self.kg[e]) >= self.n_neighbor:\n",
    "                neighbors = random.sample(self.kg[e], self.n_neighbor)\n",
    "            else:\n",
    "                neighbors = random.choices(self.kg[e], k=self.n_neighbor)  # ì¤‘ë³µ í—ˆìš© ìƒ˜í”Œë§\n",
    "\n",
    "            self.adj_ent[e] = torch.LongTensor([ent for _, ent in neighbors])\n",
    "            self.adj_rel[e] = torch.LongTensor([rel for rel, _ in neighbors])\n",
    "\n",
    "    def forward(self, u, v): # forward í˜¸ì¶œ ì‹œ (user, item) ìŒ ì…ë ¥ â†’ user-aware item score ì¶œë ¥ / u: [batch_size], v: [batch_size]\n",
    "        batch_size = u.size(0)\n",
    "        if batch_size != self.batch_size:\n",
    "            self.batch_size = batch_size\n",
    "\n",
    "        # shape ë§ì¶”ê¸°: [batch_size, 1]\n",
    "        u = u.view((-1, 1))\n",
    "        v = v.view((-1, 1))\n",
    "\n",
    "        # ì‚¬ìš©ì ì„ë² ë”©: [batch_size, dim]\n",
    "        user_embeddings = self.usr(u).squeeze(dim=1)\n",
    "\n",
    "        # itemì„ ê¸°ì¤€ìœ¼ë¡œ multi-hop ì´ì›ƒ ì—”í‹°í‹°/ê´€ê³„ ê°€ì ¸ì˜¤ê¸°\n",
    "        entities, relations = self._get_neighbors(v)\n",
    "\n",
    "        # ì´ì›ƒ ì •ë³´ë¥¼ user-aware ë°©ì‹ìœ¼ë¡œ aggregation\n",
    "        item_embeddings = self._aggregate(user_embeddings, entities, relations)\n",
    "\n",
    "        # ìµœì¢… user-item score ê³„ì‚°: ë‚´ì  í›„ sigmoid\n",
    "        scores = (user_embeddings * item_embeddings).sum(dim=1)\n",
    "\n",
    "        return torch.sigmoid(scores)\n",
    "\n",
    "    def _get_neighbors(self, v): # ì—”í‹°í‹° vì˜ multi-hop ì´ì›ƒë“¤ì„ adj matrix ê¸°ë°˜ìœ¼ë¡œ ìƒ˜í”Œë§ / v: [batch_size, 1] â†’ 1-hop, 2-hop ...ê¹Œì§€ ìŒ“ì„\n",
    "        entities = [v]  # 0-hop (ìê¸° ìì‹ )\n",
    "        relations = []\n",
    "\n",
    "        for h in range(self.n_iter):  # hop ìˆ˜ë§Œí¼ ë°˜ë³µ\n",
    "            # í˜„ì¬ hopì˜ ì—”í‹°í‹°ì—ì„œ ì´ì›ƒ ì¶”ì¶œ\n",
    "            neighbor_entities = torch.LongTensor(self.adj_ent[entities[h].cpu()]) \\\n",
    "                                    .view((self.batch_size, -1)).to(self.device)\n",
    "            neighbor_relations = torch.LongTensor(self.adj_rel[entities[h].cpu()]) \\\n",
    "                                    .view((self.batch_size, -1)).to(self.device)\n",
    "\n",
    "            entities.append(neighbor_entities)\n",
    "            relations.append(neighbor_relations)\n",
    "\n",
    "        return entities, relations\n",
    "\n",
    "    def _aggregate(self, user_embeddings, entities, relations): # Aggregatorë¥¼ ì‚¬ìš©í•´ multi-hop ì´ì›ƒ ì •ë³´ë¥¼ í†µí•©\n",
    "        # user_embeddings: [batch_size, dim]\n",
    "        # entities: hopë³„ entity ë¦¬ìŠ¤íŠ¸\n",
    "        # relations: hopë³„ relation ë¦¬ìŠ¤íŠ¸\n",
    "        \n",
    "        # hop ë³„ë¡œ entity / relation ì„ë² ë”© ì¶”ì¶œ\n",
    "        entity_vectors = [self.ent(entity) for entity in entities]\n",
    "        relation_vectors = [self.rel(relation) for relation in relations]\n",
    "\n",
    "        # hop ìˆ˜ë§Œí¼ ë°˜ë³µì ìœ¼ë¡œ aggregation\n",
    "        for i in range(self.n_iter):\n",
    "            # ë§ˆì§€ë§‰ hopì€ tanh, ê·¸ ì™¸ëŠ” sigmoid\n",
    "            act = torch.tanh if i == self.n_iter - 1 else torch.sigmoid\n",
    "\n",
    "            entity_vectors_next_iter = []\n",
    "            for hop in range(self.n_iter - i):\n",
    "                vector = self.aggregator(\n",
    "                    self_vectors=entity_vectors[hop],\n",
    "                    neighbor_vectors=entity_vectors[hop + 1] \\\n",
    "                        .view((self.batch_size, -1, self.n_neighbor, self.dim)),\n",
    "                    neighbor_relations=relation_vectors[hop] \\\n",
    "                        .view((self.batch_size, -1, self.n_neighbor, self.dim)),\n",
    "                    user_embeddings=user_embeddings,\n",
    "                    act=act\n",
    "                )\n",
    "                entity_vectors_next_iter.append(vector)\n",
    "\n",
    "            # ë‹¤ìŒ hopì˜ ê²°ê³¼ë¡œ ê°±ì‹ \n",
    "            entity_vectors = entity_vectors_next_iter\n",
    "\n",
    "        # ìµœì¢… item ì„ë² ë”© ë°˜í™˜\n",
    "        return entity_vectors[0].view((self.batch_size, self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct knowledge graph ... Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1217</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1648</td>\n",
       "      <td>4018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596</td>\n",
       "      <td>8885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>475</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1450</td>\n",
       "      <td>5171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42341</th>\n",
       "      <td>1778</td>\n",
       "      <td>1663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42342</th>\n",
       "      <td>519</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42343</th>\n",
       "      <td>1487</td>\n",
       "      <td>2879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42344</th>\n",
       "      <td>1115</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42345</th>\n",
       "      <td>793</td>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42346 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID  label\n",
       "0        1217     289      1\n",
       "1        1648    4018      0\n",
       "2         596    8885      0\n",
       "3         475      57      1\n",
       "4        1450    5171      0\n",
       "...       ...     ...    ...\n",
       "42341    1778    1663      0\n",
       "42342     519       4      1\n",
       "42343    1487    2879      1\n",
       "42344    1115      36      1\n",
       "42345     793     709      0\n",
       "\n",
       "[42346 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg = data_loader.load_kg()\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset í´ë˜ìŠ¤ ì •ì˜\n",
    "class KGCNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df): # df: í•™ìŠµìš© ë°ì´í„°í”„ë ˆì„ (userID, itemID, label í¬í•¨)\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self): # ì „ì²´ ìƒ˜í”Œ ê°œìˆ˜ ë°˜í™˜ â†’ DataLoaderì—ì„œ ì „ì²´ ë°ì´í„° í¬ê¸° ì¸ì‹ìš©\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx): # ì¸ë±ìŠ¤ idxì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë°˜í™˜ â†’ DataLoaderê°€ ë°°ì¹˜ ë‹¨ìœ„ë¡œ í˜¸ì¶œí•  ë•Œ ì‚¬ìš©ë¨\n",
    "        user_id = np.array(self.df.iloc[idx]['userID']) # ì‚¬ìš©ì ID\n",
    "        item_id = np.array(self.df.iloc[idx]['itemID']) # ì•„ì´í…œ (entity) ID\n",
    "        label = np.array(self.df.iloc[idx]['label'], dtype=np.float32) # ì´ì§„ ë¼ë²¨ (float32ë¡œ ë³€í™˜)\n",
    "\n",
    "        return user_id, item_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct knowledge graph ... Done\n",
      "ëª¨ë¸ ë° ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# í…ì„œ ë°ì´í„°ì…‹ êµ¬ì„±\n",
    "train_data = TensorDataset(\n",
    "    torch.LongTensor(df_dataset['userID'].values),\n",
    "    torch.LongTensor(df_dataset['itemID'].values),\n",
    "    torch.FloatTensor(df_dataset['label'].values)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ìˆ˜ì¹˜ ì •ë³´\n",
    "n_user, n_entity, n_relation = data_loader.get_num()\n",
    "kg_dict = data_loader.load_kg()\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (config í†µí•© ë²„ì „ì˜ KGCN í´ë˜ìŠ¤ ì‚¬ìš©)\n",
    "model = KGCN(num_user=n_user, num_ent=n_entity, num_rel=n_relation, kg=kg_dict, config=config).to(device)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í•  (config['train_ratio'] ì‚¬ìš©)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_dataset,\n",
    "    df_dataset['label'],\n",
    "    test_size=1 - config['train_ratio'],\n",
    "    shuffle=False,               # ì‹œê³„ì—´ ë°ì´í„°ë©´ False, ëœë¤ì´ë©´ True\n",
    "    random_state=999             # ì¬í˜„ì„± ë³´ì¥ì„ ìœ„í•œ ê³ ì • seed\n",
    ")\n",
    "\n",
    "# ì»¤ìŠ¤í…€ Dataset í´ë˜ìŠ¤ í™œìš©\n",
    "train_dataset = KGCNDataset(x_train)\n",
    "test_dataset = KGCNDataset(x_test)\n",
    "\n",
    "# DataLoader êµ¬ì„± (config ì‚¬ìš©)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš©ì, ì—”í‹°í‹°, ê´€ê³„ ìˆ˜ ì–»ê¸°\n",
    "num_user, num_entity, num_relation = data_loader.get_num()\n",
    "\n",
    "# ì¸ì½”ë”ë“¤ (ì›í•œë‹¤ë©´ ì¶”í›„ ë””ì½”ë”©ì— ì‚¬ìš© ê°€ëŠ¥)\n",
    "user_encoder, entity_encoder, relation_encoder = data_loader.get_encoders()\n",
    "\n",
    "# KGCN ëª¨ë¸ ìƒì„± (config ê¸°ë°˜)\n",
    "net = KGCN(num_user, num_entity, num_relation, kg_dict, config).to(device)\n",
    "\n",
    "# Binary Cross Entropy Loss (sigmoid + float labelì— ì í•©)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Adam ì˜µí‹°ë§ˆì´ì € (í•™ìŠµë¥  + L2 ì •ê·œí™”ëŠ” configì—ì„œ)\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(),\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['l2_weight']\n",
    ")\n",
    "\n",
    "print('device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.0593\n",
      "[Epoch 1] Test Loss: 1.0450 | AUC: 0.4985\n",
      "[Epoch 2] Train Loss: 0.9810\n",
      "[Epoch 2] Test Loss: 0.9757 | AUC: 0.4980\n",
      "[Epoch 3] Train Loss: 0.9045\n",
      "[Epoch 3] Test Loss: 0.9077 | AUC: 0.4978\n",
      "[Epoch 4] Train Loss: 0.8360\n",
      "[Epoch 4] Test Loss: 0.8460 | AUC: 0.4967\n",
      "[Epoch 5] Train Loss: 0.7820\n",
      "[Epoch 5] Test Loss: 0.7957 | AUC: 0.4950\n",
      "[Epoch 6] Train Loss: 0.7414\n",
      "[Epoch 6] Test Loss: 0.7594 | AUC: 0.4933\n",
      "[Epoch 7] Train Loss: 0.7163\n",
      "[Epoch 7] Test Loss: 0.7357 | AUC: 0.4906\n",
      "[Epoch 8] Train Loss: 0.7017\n",
      "[Epoch 8] Test Loss: 0.7219 | AUC: 0.4883\n",
      "[Epoch 9] Train Loss: 0.6943\n",
      "[Epoch 9] Test Loss: 0.7140 | AUC: 0.4879\n",
      "[Epoch 10] Train Loss: 0.6903\n",
      "[Epoch 10] Test Loss: 0.7094 | AUC: 0.4864\n",
      "[Epoch 11] Train Loss: 0.6884\n",
      "[Epoch 11] Test Loss: 0.7067 | AUC: 0.4868\n",
      "[Epoch 12] Train Loss: 0.6874\n",
      "[Epoch 12] Test Loss: 0.7048 | AUC: 0.4870\n",
      "[Epoch 13] Train Loss: 0.6866\n",
      "[Epoch 13] Test Loss: 0.7039 | AUC: 0.4859\n",
      "[Epoch 14] Train Loss: 0.6859\n",
      "[Epoch 14] Test Loss: 0.7030 | AUC: 0.4864\n",
      "[Epoch 15] Train Loss: 0.6855\n",
      "[Epoch 15] Test Loss: 0.7023 | AUC: 0.4860\n",
      "[Epoch 16] Train Loss: 0.6851\n",
      "[Epoch 16] Test Loss: 0.7018 | AUC: 0.4871\n",
      "[Epoch 17] Train Loss: 0.6844\n",
      "[Epoch 17] Test Loss: 0.7015 | AUC: 0.4874\n",
      "[Epoch 18] Train Loss: 0.6839\n",
      "[Epoch 18] Test Loss: 0.7012 | AUC: 0.4876\n",
      "[Epoch 19] Train Loss: 0.6833\n",
      "[Epoch 19] Test Loss: 0.7009 | AUC: 0.4876\n",
      "[Epoch 20] Train Loss: 0.6825\n",
      "[Epoch 20] Test Loss: 0.7005 | AUC: 0.4889\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "test_loss_list = []\n",
    "auc_score_list = []\n",
    "\n",
    "# í•™ìŠµ ì—í­ ë°˜ë³µ\n",
    "for epoch in range(config['n_epochs']):\n",
    "    net.train()  # í•™ìŠµ ëª¨ë“œ\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 1 epoch ë™ì•ˆ ì „ì²´ ë°°ì¹˜ í•™ìŠµ\n",
    "    for user_ids, item_ids, labels in train_loader:\n",
    "        user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(user_ids, item_ids)  # forward\n",
    "        loss = criterion(outputs, labels)  # BCE loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # ì—í­ë³„ í‰ê·  í•™ìŠµ ì†ì‹¤ ì €ì¥ ë° ì¶œë ¥\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    loss_list.append(avg_train_loss)\n",
    "    print(f'[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        total_auc = 0\n",
    "\n",
    "        for user_ids, item_ids, labels in test_loader:\n",
    "            user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(user_ids, item_ids)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # AUC ê³„ì‚° (label, ì˜ˆì¸¡ í™•ë¥ )\n",
    "            total_auc += roc_auc_score(labels.cpu().numpy(), outputs.cpu().numpy())\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        avg_auc = total_auc / len(test_loader)\n",
    "\n",
    "        test_loss_list.append(avg_test_loss)\n",
    "        auc_score_list.append(avg_auc)\n",
    "\n",
    "        print(f'[Epoch {epoch+1}] Test Loss: {avg_test_loss:.4f} | AUC: {avg_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
