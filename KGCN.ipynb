{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KGCN 논문 리뷰 & 코드 작성\n",
    "**KGCN: Simplifying and Powering Graph Convolution Network for Recommendation**  \n",
    "*Hongwei Wang et al. (2019)*  \n",
    "🔗 [논문 링크](https://arxiv.org/abs/1904.12575)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Problem Formulation\n",
    "\n",
    "*목표 : 사용자 u가 아이템 v에 관심 있을지를 예측하는 함수*\n",
    "$$\\hat{y}_{uv} = F(u,v | Θ, Y, G)$$\n",
    "- Y : 사용자-아이템 상호작용 행렬 (예: 클릭, 평가)\n",
    "- G : 지식 그래프 (KG), 삼중항(triple : head, relation, tail)의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 KGCN Layer (모델 구성 요소)\n",
    "\n",
    "*1. 관계 중요도 계산 (사용자 u, 관계 r)*\n",
    "$$\\pi_{ur} = g(u,r)$$\n",
    "\n",
    "*2. 이웃 노드 집계 (attention 가중치 포함)*\n",
    "$$v_u^{N(v)} = \\sigma_{e\\in{N(v)}}\\tilde{\\pi}_{ur}⋅e$$\n",
    "$$\\tilde{\\pi}_{ur}=\\frac{exp(\\pi_{ur})}{\\sum\\nolimits_{e'}exp(\\pi_{ur'})}$$\n",
    "\n",
    "*3. Aggregation 방식 3가지*\n",
    "- Sum : $ReLU(W(v+v_u^{N(v)})+b)$\n",
    "- Concat : $ReLU(W[v;v_u^{N(v)}]+b)$\n",
    "- Neighbor : $ReLU(Wv_u^{N(v)}+b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Learning Algorithm (학습 알고리즘)\n",
    "\n",
    "*반복 구조*\n",
    "KGCN은 여러 계층(hop)으로 구성되어 '0-hop → 1-hop → ...'와 같은 형식으로 이웃 정보를 반복적으로 전파 및 집계\n",
    "$$\\hat{y}_{uv}=f(u, v_u^{(h)})$$\n",
    "\n",
    "*학습 손실 함수*\n",
    "- Cross Entropy + Negative Sampling + L2 정규화 포함\n",
    "$$L = \\sum_{u}\\begin{bmatrix}\\sum_{v:y_{uv}=1}J(y_{uv}, \\hat{y}_{uv})-\\sum_{i=1}^{T_u}\\mathbb{E}_{vi~P(v)}J(0,\\hat{y}_(uvi))\\end{bmatrix}+\\lambda||F||_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\"))\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book - Crossing 모델 설정 (Hyperparameter)\n",
    "\n",
    "|항목|설정|\n",
    "|:---:|:---:|\n",
    "임베딩 차원 | 64\n",
    "학습률 | 0.0002\n",
    "Optimizer | Adam\n",
    "정규화 계수 (L2) | 2e-5\n",
    "Negative Sampling | 1:1 비율로 샘플링\n",
    "배치 사이즈 | 256\n",
    "학습 Epoch | 최대 1000 (일반적으로 200~400)\n",
    "레이어 수 (Receptive Field Depth, H) | 1\n",
    "이웃 샘플링 수 (K) | 8\n",
    "초기화 방식 | Xavier Uniform (명시는 없지만 일반적인 초기화 방식으로 추정됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': 'mps',\n",
    "    'dataset': 'book',\n",
    "    'embedding_dim': 64,\n",
    "    'n_layers': 1,\n",
    "    'lr': 0.0002,\n",
    "    'batch_size': 256,\n",
    "    'l2': 2e-5,\n",
    "    'n_epoch': 200,\n",
    "    'n_neighbor': 8,\n",
    "    'H': 1,\n",
    "    'aggregator': 'sum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kg(file_path):\n",
    "    kg = dict()\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            h, r, t = map(int, line.strip().split())\n",
    "            if h not in kg:\n",
    "                kg[h] = []\n",
    "            kg[h].append((t, r))\n",
    "            if t not in kg:\n",
    "                kg[t] = []\n",
    "            kg[t].append((h, r))\n",
    "    return kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KGCN(nn.Module):\n",
    "    def __init__(self, n_users, n_entities, n_relations, kg, config):\n",
    "        super(KGCN, self).__init__()\n",
    "        self.embedding_dim = config['embedding_dim']\n",
    "        self.n_layers = config['n_layers']\n",
    "        self.n_neighbors = config['n_neighbor']\n",
    "        self.aggregator_type = config['aggregator']\n",
    "        self.device = config['device']\n",
    "        self.kg = kg\n",
    "\n",
    "        self.user_emb = nn.Embedding(n_users, self.embedding_dim)\n",
    "        self.entity_emb = nn.Embedding(n_entities, self.embedding_dim)\n",
    "        self.relation_emb = nn.Embedding(n_relations, self.embedding_dim)\n",
    "\n",
    "        self.W = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def aggregate(self, entity_vectors, neighbor_vectors, neighbor_relations, user_vector):\n",
    "        user_vector = user_vector.unsqueeze(1)\n",
    "        scores = torch.sum(user_vector * neighbor_relations, dim=-1, keepdim=True)\n",
    "        att_weights = torch.softmax(scores, dim=1)\n",
    "        weighted_neighbors = torch.sum(att_weights * neighbor_vectors, dim=1)\n",
    "\n",
    "        if self.aggregator_type == 'sum':\n",
    "            out = entity_vectors + weighted_neighbors\n",
    "        elif self.aggregator_type == 'concat':\n",
    "            out = torch.cat([entity_vectors, weighted_neighbors], dim=-1)\n",
    "            out = self.W(out)\n",
    "        elif self.aggregator_type == 'neighbor':\n",
    "            out = weighted_neighbors\n",
    "        else:\n",
    "            raise ValueError(\"Unknown aggregator type\")\n",
    "\n",
    "        return self.activation(out)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_vector = self.user_emb(user_ids)\n",
    "        entity_vector = self.entity_emb(item_ids)\n",
    "        neighbor_vectors = self.get_neighbors(item_ids, hop=1)\n",
    "\n",
    "        for _ in range(self.n_layers):\n",
    "            entity_vector = self.aggregate(entity_vector, *neighbor_vectors, user_vector)\n",
    "            neighbor_vectors = self.get_neighbors(item_ids, hop=1)\n",
    "\n",
    "        scores = torch.sum(entity_vector * user_vector, dim=1)\n",
    "        return torch.sigmoid(scores)\n",
    "\n",
    "    def get_neighbors(self, entity_ids, hop=1):\n",
    "        batch_neighbors = []\n",
    "        batch_relations = []\n",
    "\n",
    "        for eid in entity_ids.cpu().numpy():\n",
    "            neighbors = self.kg.get(eid, [])\n",
    "            if len(neighbors) == 0:\n",
    "                neighbors = [(eid, 0)] * self.n_neighbors\n",
    "            elif len(neighbors) < self.n_neighbors:\n",
    "                neighbors = neighbors + random.choices(neighbors, k=self.n_neighbors - len(neighbors))\n",
    "            else:\n",
    "                neighbors = random.sample(neighbors, self.n_neighbors)\n",
    "\n",
    "            e_ids = [e for e, r in neighbors]\n",
    "            r_ids = [r for e, r in neighbors]\n",
    "            batch_neighbors.append(e_ids)\n",
    "            batch_relations.append(r_ids)\n",
    "\n",
    "        neighbor_entities = torch.tensor(batch_neighbors, device=self.device)\n",
    "        neighbor_relations = torch.tensor(batch_relations, device=self.device)\n",
    "\n",
    "        neighbor_entity_emb = self.entity_emb(neighbor_entities)\n",
    "        neighbor_relation_emb = self.relation_emb(neighbor_relations)\n",
    "\n",
    "        return neighbor_entity_emb, neighbor_relation_emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
